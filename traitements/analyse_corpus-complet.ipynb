{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2972114f",
   "metadata": {},
   "source": [
    "**PARTIE 2 ANALYSE DONNEES :**\n",
    "\n",
    "- ~~FILTRE SPAM : enlever ceux qui sont pas en fr~~\n",
    "- ~~co-occurrences (bigrammes/trigrammes de mots ? hors mots vides ?)~~\n",
    "- ~~regarder tokens les + fqts (hors mots vides)~~\n",
    "- ~~entités les + fqtes ~~\n",
    "- noms de sentiments les + fqts\n",
    "- polarité la + représentée\n",
    "- essayer aspect diachronique : évolution hashtags (graphiques ?)\n",
    "- ~~nombre d'auteurs différents (avec author_id, pour voir si gens ont tendance à faire un ou pls tweets dessus) ~~\n",
    "- ~~langue (que fr détecté ?)~~\n",
    "- ~~métriques des tweets les + partagés/moyenne~~\n",
    "- ~~stats sur corpus ((lieux des tweets/users, popularité des utilisateurs) ~~nb de tweets contenant un média et quel type)~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f84353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fanny/anaconda3/envs/main/lib/python3.10/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import json,glob\n",
    "from itertools import tee, islice\n",
    "from collections import Counter\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "\n",
    "def ouvrir_json(chemin):\n",
    "    with open(chemin, encoding=\"utf-8\") as f:\n",
    "        toto = json.load(f)\n",
    "    return toto\n",
    "\n",
    "def trier_dic(dic):\n",
    "    L = [[effectif,car] for car,effectif in dic.items()]\n",
    "    L_sorted = sorted(L, reverse=True)\n",
    "    return [[car,effectif] for effectif,car in L_sorted]\n",
    "\n",
    "\n",
    "def ngrams(lst, n): #fonction trouvée sur https://stackoverflow.com/questions/12488722/counting-bigrams-pair-of-two-words-in-a-file-using-python\n",
    "    tlst = lst\n",
    "    while True:\n",
    "        a, b = tee(tlst)\n",
    "        l = tuple(islice(a, n))\n",
    "        if len(l) == n:\n",
    "            yield l\n",
    "            next(b)\n",
    "            tlst = b\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e98b4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types média {'photo': 2278, 'video': 430, 'animated_gif': 99}\n",
      "\n",
      "Langues :  {'fr': 8109}\n",
      "\n",
      "Dates :  {'2023-02-04': 542, '2023-02-01': 400, '2023-01-18': 470, '2023-01-21': 200, '2023-01-29': 300, '2023-02-02': 400, '2023-02-05': 610, '2023-01-26': 300, '2023-02-06': 547, '2023-02-07': 199, '2023-01-23': 400, '2023-01-22': 200, '2023-02-03': 500, '2023-01-28': 400, '2023-01-25': 300, '2023-01-17': 193, '2023-01-19': 455, '2023-01-27': 200, '2023-01-20': 300, '2023-01-30': 299, '2023-01-31': 499, '2023-01-24': 300, '2023-01-16': 95}\n",
      "\n",
      "Auteurs uniques 5333 et les plus présents [['1564885347120603138', 175], ['306751565', 41], ['1218447306061754369', 34], ['85362553', 33], ['2966670748', 30]]\n",
      "\n",
      "Nombre moyen de followers 438438.79  nombre max : [78704924, 87679850, 126697122, 126727561, 126941873]\n",
      "\n",
      "Max de RT :  99 / max de rép : 81 / max de likes :  389\n",
      "\n",
      "Moyennes de RT :  0.5299050437785177 / de rép : 0.20113454186706128 / de likes :  1.2114934023924036\n",
      "\n",
      "Hashtags :  [['reformedesretraites', 945], ['retraite', 277], ['retraites', 216], ['travail', 171], ['réforme', 168], ['viechère', 164], ['réformedesretraites', 138], ['macron', 119], ['greve31janvier', 112], ['greve19janvier', 93], ['directan', 79], ['nupes', 71], ['reformesdesretraites', 68], ['greve7fevrier', 59], ['grevegenerale', 41], ['macronie', 40], ['lfi', 36], ['nonalareformedesretraites', 35], ['france', 32], ['64anscestnon', 30], ['cgt', 29], ['manif7fevrier', 27], ['referendum', 25], ['cotisations', 25], ['grevegeneraleillimitee', 23], ['borne', 23], ['grevegenerale19janvier', 21], ['greve11fevrier', 21], ['francais', 21], ['manif31janvier', 16], ['toulouse', 15], ['stopretraitemacron', 15], ['politique', 14], ['marche21janvier', 14], ['renaissance', 13], ['manif19janvier', 13], ['dussopt', 13], ['covid19', 13], ['macrondegage', 12], ['greve', 12], ['rn', 11], ['manifestation', 11], ['lrem', 11], ['debatbfmtv', 11], ['zelenskyy', 10], ['ursula', 10], ['srfclosc', 10], ['psgtfc', 10], ['paris', 10], ['hakimi', 10]]\n",
      "\n",
      "Mentions :  [['BFMTV', 413], ['Elisabeth_Borne', 372], ['EmmanuelMacron', 250], ['olivierdussopt', 221], ['DeputesRE', 183], ['CNEWS', 148], ['olivierveran', 139], ['franceinfo', 118], ['MaudBregeon', 117], ['JLMelenchon', 104], ['auroreberge', 93], ['Renaissance', 89], ['MathildePanot', 84], ['gouvernementFR', 81], ['GabrielAttal', 80], ['priscathevenot', 75], ['BrunoLeMaire', 75], ['LCI', 68], ['SylvainMaillard', 67], ['VSPILLEBOUT', 66], ['benjaminhaddad', 64], ['MLP_officiel', 64], ['FranceInsoumise', 64], ['lesRepublicains', 63], ['midy_paul', 61], ['GDarmanin', 59], ['tcabarrus', 51], ['Francois_Ruffin', 50], ['Clem_Autain', 50], ['AssembleeNat', 50], ['MathieuMlefevre', 49], ['J_Bardella', 49], ['RNational_off', 47], ['YouTube', 45], ['ECiotti', 45], ['ALeaument', 42], ['guillaumekasba', 40], ['LouisBoyard', 39], ['2022Elections', 36], ['stephanie_rist', 35], ['leJDD', 35], ['CFDT', 34], ['GG_RMC', 33], ['franceinter', 32], ['SabrinaRoubache', 31], ['Ecrins6', 31], ['sandrousseau', 30], ['Europe1', 30], ['steph_sejourne', 29], ['CfdtBerger', 29]]\n",
      "\n",
      "Tokens :  [['retraite', 3332], ['réforme', 1871], ['ans', 1454], ['contre', 993], ['macron', 875], ['retraites', 749], ['départ', 669], ['faire', 597], ['français', 549], ['non', 423], ['bien', 419], ['projet', 342], ['faut', 340], ['gouvernement', 314], ['âge', 311], ['france', 279], ['veut', 272], ['système', 265], ['rien', 262], ['partir', 260], ['travailler', 255], ['taux', 229], ['vie', 221], ['grève', 202], ['pays', 196], ['travail', 195], ['riches', 191], ['millions', 177], ['légal', 176], ['monde', 172], ['mobilisation', 170], ['été', 168], ['voter', 168], ['taxer', 159], ['députés', 159], ['femmes', 158], ['injuste', 155], ['êtes', 154], ['janvier', 154], ['peuple', 153], ['personnes', 153], ['avez', 152], ['temps', 151], ['oui', 151], ['jamais', 147], ['demander', 147], ['prendre', 145], ['place', 145], ['l', 139], ['rue', 138]]\n",
      "\n",
      "\n",
      "Bigrammes :  [(('de', 'la'), 2042), (('la', 'retraite'), 1702), (('à', 'la'), 1298), (('la', 'réforme'), 847), (('la', '#reformedesretraites'), 631), (('retraite', 'à'), 629), (('contre', 'la'), 613), (('réforme', 'des'), 581), ((\"l'âge\", 'de'), 550), (('des', 'retraites'), 542), (('de', 'départ'), 530), (('départ', 'à'), 463), (('de', 'retraite'), 414), (('pour', 'la'), 342), (('pour', 'les'), 338), (('sur', 'la'), 338), (('dans', 'la'), 290), (('cette', 'réforme'), 287), (('à', '64'), 280), (('l’âge', 'de'), 271)]\n",
      "\n",
      "Trigrammes :  [(('de', 'la', 'retraite'), 550), (('à', 'la', 'retraite'), 526), (('la', 'retraite', 'à'), 417), (('départ', 'à', 'la'), 395), (('de', 'départ', 'à'), 384), (('la', 'réforme', 'des'), 370), (('réforme', 'des', 'retraites'), 370), ((\"l'âge\", 'de', 'la'), 254), ((\"l'âge\", 'de', 'départ'), 232), (('contre', 'la', '#reformedesretraites'), 220), (('contre', 'la', 'réforme'), 200), (('des', 'retraites', ':'), 176), (('#viechère', '#réforme', '#travail'), 170), (('#réforme', '#travail', '#retraite'), 168), (('à', '64', 'ans'), 153), (('retraite', 'à', '64'), 143), (('il', 'y', 'a'), 139), (('l’âge', 'de', 'la'), 137), (('la', 'réforme', 'de'), 133), (('de', \"l'âge\", 'de'), 125)]\n",
      "\n",
      "\n",
      "Bigrammes sans mots grammaticaux :  [(('réforme', 'retraites'), 460), (('retraite', 'ans'), 379), (('départ', 'retraite'), 338), (('réforme', 'retraite'), 263), (('contre', 'réforme'), 258), (('taxer', 'ultra'), 121), (('ultra', 'riches'), 121), (('effort', 'financier'), 121), (('financier', 'demander'), 121), (('demander', 'gagne'), 103), (('système', 'retraite'), 99), (('légal', 'départ'), 95), (('taux', 'ans'), 92), (('riches', 'millions'), 88), (('millions', 'effort'), 88), (('partir', 'retraite'), 87), (('ans', 'taux'), 76), (('motion', 'référendaire'), 67), (('travailler', 'ans'), 66), (('retraite', 'macron'), 64)]\n",
      "\n",
      "Trigrammes sans mots grammaticaux :  [(('taxer', 'ultra', 'riches'), 121), (('effort', 'financier', 'demander'), 121), (('financier', 'demander', 'gagne'), 103), (('contre', 'réforme', 'retraites'), 98), (('ultra', 'riches', 'millions'), 88), (('riches', 'millions', 'effort'), 88), (('millions', 'effort', 'financier'), 88), (('ans', 'taux', 'ans'), 64), (('taux', 'ans', 'demeure'), 46), (('nettement', 'inférieur', 'ans'), 46), (('légal', 'départ', 'retraite'), 45), (('taux', 'ans', 'taux'), 45), (('ans', 'demeure', 'toutefois'), 45), (('demeure', 'toutefois', 'nettement'), 45), (('toutefois', 'nettement', 'inférieur'), 45), (('contre', 'réforme', 'retraite'), 38), (('départ', 'retraite', 'ans'), 35), (('revenons', 'taxer', 'ultra'), 33), (('ultra', 'riches', 'effort'), 33), (('riches', 'effort', 'financier'), 33)]\n"
     ]
    }
   ],
   "source": [
    "#variables de base du corpus\n",
    "\n",
    "nb_media = 0\n",
    "types_media = {}\n",
    "\n",
    "followers=[]\n",
    "loc_users={}\n",
    "\n",
    "lg = {}\n",
    "tokens = {}\n",
    "mentions = {}\n",
    "hashtags = {}\n",
    "authors = {}\n",
    "dates = {}\n",
    "total_text = \"\"\n",
    "total_text_sw = \"\"\n",
    "\n",
    "nb_url=0\n",
    "rt, rep, like = [], [], []\n",
    "\n",
    "for doc in glob.glob(\"corpus_projet_plus/*\"):\n",
    "    corpus = ouvrir_json(doc)\n",
    "    #dico structure : 3 grandes clés : data, includes (media), meta\n",
    "    data = corpus[\"data\"]\n",
    "    includes = corpus[\"includes\"]\n",
    "    meta = corpus[\"meta\"]\n",
    "    \n",
    "    \"\"\"PARTIE INCLUDES/MEDIAS\"\"\"\n",
    "    #nombre de tweets contenant un média\n",
    "    nb_media += len(includes[\"media\"])\n",
    "    for media in includes[\"media\"]:\n",
    "        types_media[media[\"type\"]] = types_media.get(media[\"type\"], 0) + 1\n",
    "        \n",
    "    \"\"\"PARTIE INCLUDES/USERS\"\"\"\n",
    "    #nb d'id uniques, moy et max de followers, location\n",
    "    for user in includes[\"users\"]:\n",
    "        followers.append(user[\"public_metrics\"][\"followers_count\"])\n",
    "        try:\n",
    "            loc_users[user[\"location\"]] = loc_users.get(user[\"location\"], 0) + 1 #pas trop utile car pas normalisé\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    \"\"\"PARTIE DATA\"\"\"\n",
    "\n",
    "    for tweet in data:\n",
    "        \"\"\"TEXT\"\"\"\n",
    "        text = tweet[\"text\"].lower()\n",
    "        total_text += tweet[\"text\"].lower()\n",
    "\n",
    "        #tokens les + fréquents (hors mots vides)\n",
    "        for token in text.split():\n",
    "        #for token in word_tokenize(text.lower(), language='french'): #peut-être pas une bonne idée > pb pour les mentions, liens et hashtags\n",
    "            if token not in fr_stop and token.isalpha():\n",
    "                tokens[token] = tokens.get(token, 0) + 1\n",
    "                total_text_sw += \" \"+token        \n",
    "\n",
    "        \"\"\"ENTITIES : mentions (nb+dico username), urls (nb), hashtags (nb+ dico tags)\"\"\"\n",
    "        try: #pour éviter pb des tweets sans entités détectées\n",
    "            for mention in tweet[\"entities\"][\"mentions\"]:\n",
    "                mentions[mention[\"username\"]] = mentions.get(mention[\"username\"], 0) + 1\n",
    "\n",
    "            nb_url += len(tweet[\"entities\"][\"urls\"]) \n",
    "\n",
    "            for ht in tweet[\"entities\"][\"hashtags\"]:\n",
    "                hashtags[ht[\"tag\"].lower()] = hashtags.get(ht[\"tag\"].lower(), 0) + 1\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \"\"\"LANG\"\"\"\n",
    "        lg[tweet['lang']] = lg.get(tweet['lang'], 0) + 1\n",
    "        if tweet['lang']!='fr':\n",
    "            print(text)\n",
    "            print(\"********\")\n",
    "\n",
    "        \"\"\"AUTHOR_ID\"\"\"\n",
    "        authors[tweet[\"author_id\"]] = authors.get(tweet[\"author_id\"],0)+1\n",
    "\n",
    "        \"\"\"CREATED_AT : pas les heures, donc slmt 10 premiers car de la date\"\"\"\n",
    "        dates[tweet[\"created_at\"][:10]] = dates.get(tweet[\"created_at\"][:10], 0)+1\n",
    "\n",
    "        \"\"\"PUBLIC_METRICS : retweet_count, reply_count, like_count, (quote_count, impression_count) => moy et max\"\"\"\n",
    "        rt.append(tweet[\"public_metrics\"][\"retweet_count\"])\n",
    "        rep.append(tweet[\"public_metrics\"][\"reply_count\"])\n",
    "        like.append(tweet[\"public_metrics\"][\"like_count\"])\n",
    "\n",
    "        \n",
    "print(\"Types média\", types_media)\n",
    "print(\"\\nLangues : \",lg)\n",
    "print(\"\\nDates : \", dates)\n",
    "print(\"\\nAuteurs uniques\", len(authors), \"et les plus présents\", trier_dic(authors)[:5])\n",
    "print(\"\\nNombre moyen de followers\", round(sum(followers)/len(followers),2), \" nombre max :\", sorted(followers)[-5:])\n",
    "print(\"\\nMax de RT : \", max(rt), \"/ max de rép :\", max(rep), \"/ max de likes : \", max(like))\n",
    "print(\"\\nMoyennes de RT : \", sum(rt)/len(rt), \"/ de rép :\", sum(rep)/len(rep), \"/ de likes : \", sum(like)/len(like))\n",
    "print(\"\\nHashtags : \",trier_dic(hashtags)[:50])\n",
    "print(\"\\nMentions : \",trier_dic(mentions)[:50])\n",
    "print(\"\\nTokens : \",trier_dic(tokens)[:50])\n",
    "\n",
    "bigr = Counter(ngrams(total_text.split(), 2))\n",
    "trigr = Counter(ngrams(total_text.split(), 3))\n",
    "print(\"\\n\\nBigrammes : \", bigr.most_common(20))\n",
    "print(\"\\nTrigrammes : \", trigr.most_common(20))\n",
    "\n",
    "bigr_sw = Counter(ngrams(total_text_sw.split(), 2))\n",
    "trigr_sw = Counter(ngrams(total_text_sw.split(), 3))\n",
    "print(\"\\n\\nBigrammes sans mots grammaticaux : \", bigr_sw.most_common(20))\n",
    "print(\"\\nTrigrammes sans mots grammaticaux : \", trigr_sw.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4e7be55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zxx https://t.co/30yzrhspgv\n",
      "********\n",
      "und 🤗\n",
      "#greve19janvier \n",
      "#reformedesretraites \n",
      "#retraite https://t.co/r3t41kj905\n",
      "********\n",
      "en @brunolemaire macron #reformedesretraites #greve19janvier #lycee \n",
      "\n",
      "#grevegeneraleillimitee \n",
      "#grevegenerale19janvier \n",
      "\n",
      "https://t.co/rd3gq5aid2\n",
      "********\n",
      "qme #montedemarsan #greve19janvier #reformedesretraites #collterr #secretairedemairie https://t.co/x1x383uebv\n",
      "********\n",
      "en prue\n",
      "jay briscoe\n",
      "#brandnamesinfilmsorsongs\n",
      "premier league\n",
      "depay\n",
      "josh norris\n",
      "truth social\n",
      "memphis\n",
      "homepod\n",
      "#milaninter\n",
      "ghostface\n",
      "#pistorius\n",
      "narty\n",
      "walker howard\n",
      "#réformedesretraites\n",
      "ausgabe\n",
      "kampagne\n",
      "melonik\n",
      "nick khan https://t.co/tkzkfmlrwo\n",
      "********\n",
      "qme @alexishrzs #le19janvierjetravaille \n",
      "#reformedesretraites https://t.co/wldwne8fue\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "\"\"\"À faire qu'une fois (résolu ensuite dans la requête directement)\"\"\"\n",
    "#supprimer les tweets pas en français (récupérés avant l'ajout de la contrainte lang:fr), ne concernait qu'une soixantaine de tweets/1200\n",
    "\n",
    "for doc in glob.glob(\"corpus_projet_plus/*\"):\n",
    "    corpus = ouvrir_json(doc)\n",
    "    #dico structure : 3 grandes clés : data, includes (media), meta\n",
    "    data = corpus[\"data\"]\n",
    "    len_data = len(data)\n",
    "    includes = corpus[\"includes\"]\n",
    "    meta = corpus[\"meta\"]\n",
    "        \n",
    "    \"\"\"PARTIE DATA\"\"\"\n",
    "\n",
    "    for tweet in data:\n",
    "        \"\"\"TEXT\"\"\"\n",
    "        text = tweet[\"text\"].lower()\n",
    "\n",
    "        \"\"\"LANG\"\"\"\n",
    "        lg[tweet['lang']] = lg.get(tweet['lang'], 0) + 1\n",
    "        if tweet['lang']!='fr':\n",
    "            print(tweet['lang'],text)\n",
    "            print(\"********\")\n",
    "            data.remove(tweet)\n",
    "            \n",
    "    if len_data != len(data):\n",
    "        with open(doc, 'w') as f:\n",
    "            json.dump(corpus, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
